Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

********** Run - model: bert-base-uncased, learning rate = 2e-05 **********

********** Run 1 - input sentence pairs **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:47<05:10, 12.30it/s]{'loss': 1.5099, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:40<03:21, 12.63it/s]{'eval_loss': 1.249584674835205, 'eval_runtime': 2.0471, 'eval_samples_per_second': 668.742, 'eval_steps_per_second': 84.02, 'epoch': 1.0}

{'loss': 1.0356, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:29<01:41, 12.57it/s]{'eval_loss': 1.1026923656463623, 'eval_runtime': 2.0333, 'eval_samples_per_second': 673.301, 'eval_steps_per_second': 84.593, 'epoch': 2.0}

{'loss': 0.7876, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:21<00:00, 12.65it/s]{'eval_loss': 1.1383705139160156, 'eval_runtime': 2.034, 'eval_samples_per_second': 673.062, 'eval_steps_per_second': 84.563, 'epoch': 3.0}

{'loss': 0.6199, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.157150387763977, 'eval_runtime': 2.0707, 'eval_samples_per_second': 661.126, 'eval_steps_per_second': 83.063, 'epoch': 4.0}

{'train_runtime': 443.1197, 'train_samples_per_second': 91.912, 'train_steps_per_second': 11.491, 'train_loss': 0.9882409035082605, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.6817375886524822

                        precision    recall  f1-score   support

       Acknowledgement       0.76      0.81      0.79       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.41      0.48      0.44        33

               Comment       0.63      0.63      0.63       165

           Conditional       0.56      0.56      0.56        18

          Continuation       0.58      0.51      0.54       113

              Contrast       0.47      0.36      0.41        44

            Correction       0.44      0.19      0.27        21

           Elaboration       0.55      0.59      0.57       101

           Explanation       0.29      0.39      0.33        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.67      0.40      0.50        15

                Q_Elab       0.61      0.69      0.65        72

  Question_answer_pair       0.88      0.93      0.90       305

                Result       0.56      0.52      0.54        29

              accuracy                           0.68      1128

             macro avg       0.53      0.49      0.50      1128

          weighted avg       0.67      0.68      0.67      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:46<05:11, 12.27it/s]{'loss': 1.5479, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:39<03:24, 12.46it/s]{'eval_loss': 1.2564318180084229, 'eval_runtime': 2.0434, 'eval_samples_per_second': 669.945, 'eval_steps_per_second': 84.171, 'epoch': 1.0}

{'loss': 1.0533, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:28<01:40, 12.63it/s]{'eval_loss': 1.121106743812561, 'eval_runtime': 2.044, 'eval_samples_per_second': 669.765, 'eval_steps_per_second': 84.149, 'epoch': 2.0}

{'loss': 0.7951, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:20<00:00, 12.59it/s]{'eval_loss': 1.145859718322754, 'eval_runtime': 2.0448, 'eval_samples_per_second': 669.492, 'eval_steps_per_second': 84.114, 'epoch': 3.0}

{'loss': 0.616, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.1713142395019531, 'eval_runtime': 2.0449, 'eval_samples_per_second': 669.471, 'eval_steps_per_second': 84.112, 'epoch': 4.0}

{'train_runtime': 442.3888, 'train_samples_per_second': 92.064, 'train_steps_per_second': 11.51, 'train_loss': 1.003079590419101, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.6950354609929078

                        precision    recall  f1-score   support

       Acknowledgement       0.77      0.80      0.78       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.40      0.48      0.44        33

               Comment       0.62      0.66      0.64       165

           Conditional       0.59      0.72      0.65        18

          Continuation       0.61      0.50      0.55       113

              Contrast       0.57      0.55      0.56        44

            Correction       0.53      0.38      0.44        21

           Elaboration       0.57      0.62      0.60       101

           Explanation       0.38      0.45      0.41        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.46      0.40      0.43        15

                Q_Elab       0.67      0.68      0.68        72

  Question_answer_pair       0.88      0.91      0.90       305

                Result       0.60      0.52      0.56        29

              accuracy                           0.70      1128

             macro avg       0.54      0.53      0.53      1128

          weighted avg       0.69      0.70      0.69      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:46<05:11, 12.28it/s]{'loss': 1.5479, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:38<03:22, 12.56it/s]{'eval_loss': 1.2564318180084229, 'eval_runtime': 2.0464, 'eval_samples_per_second': 668.974, 'eval_steps_per_second': 84.049, 'epoch': 1.0}

{'loss': 1.0533, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:27<01:40, 12.63it/s]{'eval_loss': 1.121106743812561, 'eval_runtime': 2.0739, 'eval_samples_per_second': 660.112, 'eval_steps_per_second': 82.936, 'epoch': 2.0}

{'loss': 0.7951, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:19<00:00, 12.59it/s]{'eval_loss': 1.145859718322754, 'eval_runtime': 2.0491, 'eval_samples_per_second': 668.099, 'eval_steps_per_second': 83.939, 'epoch': 3.0}

{'loss': 0.616, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.1713142395019531, 'eval_runtime': 2.0477, 'eval_samples_per_second': 668.557, 'eval_steps_per_second': 83.997, 'epoch': 4.0}

{'train_runtime': 442.0526, 'train_samples_per_second': 92.134, 'train_steps_per_second': 11.519, 'train_loss': 1.003079590419101, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.6950354609929078

                        precision    recall  f1-score   support

       Acknowledgement       0.77      0.80      0.78       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.40      0.48      0.44        33

               Comment       0.62      0.66      0.64       165

           Conditional       0.59      0.72      0.65        18

          Continuation       0.61      0.50      0.55       113

              Contrast       0.57      0.55      0.56        44

            Correction       0.53      0.38      0.44        21

           Elaboration       0.57      0.62      0.60       101

           Explanation       0.38      0.45      0.41        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.46      0.40      0.43        15

                Q_Elab       0.67      0.68      0.68        72

  Question_answer_pair       0.88      0.91      0.90       305

                Result       0.60      0.52      0.56        29

              accuracy                           0.70      1128

             macro avg       0.54      0.53      0.53      1128

          weighted avg       0.69      0.70      0.69      1128

Average accuracy = 0.6906028368794326

********** Run complete **********

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

********** Run - model: bert-base-uncased, learning rate = 2e-05 **********

********** Run 2 - input question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:46<05:00, 12.73it/s]{'loss': 2.2577, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:36<03:18, 12.82it/s]{'eval_loss': 2.276870012283325, 'eval_runtime': 2.1167, 'eval_samples_per_second': 646.768, 'eval_steps_per_second': 81.259, 'epoch': 1.0}

{'loss': 2.0912, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:23<01:38, 12.89it/s]{'eval_loss': 2.3153769969940186, 'eval_runtime': 2.095, 'eval_samples_per_second': 653.463, 'eval_steps_per_second': 82.101, 'epoch': 2.0}

{'loss': 1.9272, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:13<00:00, 12.88it/s]{'eval_loss': 2.360337018966675, 'eval_runtime': 2.0938, 'eval_samples_per_second': 653.842, 'eval_steps_per_second': 82.148, 'epoch': 3.0}

{'loss': 1.7623, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.423619270324707, 'eval_runtime': 2.0978, 'eval_samples_per_second': 652.586, 'eval_steps_per_second': 81.99, 'epoch': 4.0}

{'train_runtime': 435.168, 'train_samples_per_second': 93.591, 'train_steps_per_second': 11.701, 'train_loss': 2.0096242804276314, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.26595744680851063

                        precision    recall  f1-score   support

       Acknowledgement       0.18      0.16      0.17       148

           Alternation       0.00      0.00      0.00        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.00      0.00      0.00        33

               Comment       0.24      0.67      0.35       165

           Conditional       0.50      0.06      0.10        18

          Continuation       0.20      0.10      0.13       113

              Contrast       0.27      0.09      0.14        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.14      0.12      0.13       101

           Explanation       0.33      0.10      0.15        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.00      0.00      0.00        15

                Q_Elab       0.13      0.03      0.05        72

  Question_answer_pair       0.39      0.43      0.41       305

                Result       0.00      0.00      0.00        29

              accuracy                           0.27      1128

             macro avg       0.15      0.11      0.10      1128

          weighted avg       0.23      0.27      0.22      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:45<04:56, 12.90it/s]{'loss': 2.2523, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:34<03:18, 12.84it/s]{'eval_loss': 2.277902364730835, 'eval_runtime': 2.0979, 'eval_samples_per_second': 652.547, 'eval_steps_per_second': 81.985, 'epoch': 1.0}

{'loss': 2.1002, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:21<01:38, 12.88it/s]{'eval_loss': 2.300989866256714, 'eval_runtime': 2.094, 'eval_samples_per_second': 653.768, 'eval_steps_per_second': 82.139, 'epoch': 2.0}

{'loss': 1.9397, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:11<00:00, 12.85it/s]{'eval_loss': 2.3388373851776123, 'eval_runtime': 2.0948, 'eval_samples_per_second': 653.529, 'eval_steps_per_second': 82.109, 'epoch': 3.0}

{'loss': 1.7765, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.403461456298828, 'eval_runtime': 2.0955, 'eval_samples_per_second': 653.301, 'eval_steps_per_second': 82.08, 'epoch': 4.0}

{'train_runtime': 433.5243, 'train_samples_per_second': 93.946, 'train_steps_per_second': 11.746, 'train_loss': 2.017175235433646, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.2712765957446808

                        precision    recall  f1-score   support

       Acknowledgement       0.21      0.14      0.16       148

           Alternation       0.00      0.00      0.00        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.00      0.00      0.00        33

               Comment       0.24      0.67      0.35       165

           Conditional       0.50      0.06      0.10        18

          Continuation       0.18      0.08      0.11       113

              Contrast       0.18      0.09      0.12        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.20      0.16      0.18       101

           Explanation       0.17      0.10      0.12        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.00      0.00      0.00        15

                Q_Elab       0.14      0.04      0.06        72

  Question_answer_pair       0.37      0.45      0.41       305

                Result       0.30      0.10      0.15        29

              accuracy                           0.27      1128

             macro avg       0.16      0.12      0.11      1128

          weighted avg       0.24      0.27      0.23      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:44<04:55, 12.92it/s]{'loss': 2.2523, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:34<03:18, 12.83it/s]{'eval_loss': 2.277902364730835, 'eval_runtime': 2.096, 'eval_samples_per_second': 653.135, 'eval_steps_per_second': 82.059, 'epoch': 1.0}

{'loss': 2.1002, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:20<01:43, 12.34it/s]{'eval_loss': 2.300989866256714, 'eval_runtime': 2.1257, 'eval_samples_per_second': 644.014, 'eval_steps_per_second': 80.913, 'epoch': 2.0}

{'loss': 1.9397, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:10<00:00, 12.96it/s]{'eval_loss': 2.3388373851776123, 'eval_runtime': 2.0975, 'eval_samples_per_second': 652.684, 'eval_steps_per_second': 82.003, 'epoch': 3.0}

{'loss': 1.7765, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.403461456298828, 'eval_runtime': 2.076, 'eval_samples_per_second': 659.444, 'eval_steps_per_second': 82.852, 'epoch': 4.0}

{'train_runtime': 432.5422, 'train_samples_per_second': 94.16, 'train_steps_per_second': 11.772, 'train_loss': 2.017175235433646, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.2712765957446808

                        precision    recall  f1-score   support

       Acknowledgement       0.21      0.14      0.16       148

           Alternation       0.00      0.00      0.00        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.00      0.00      0.00        33

               Comment       0.24      0.67      0.35       165

           Conditional       0.50      0.06      0.10        18

          Continuation       0.18      0.08      0.11       113

              Contrast       0.18      0.09      0.12        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.20      0.16      0.18       101

           Explanation       0.17      0.10      0.12        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.00      0.00      0.00        15

                Q_Elab       0.14      0.04      0.06        72

  Question_answer_pair       0.37      0.45      0.41       305

                Result       0.30      0.10      0.15        29

              accuracy                           0.27      1128

             macro avg       0.16      0.12      0.11      1128

          weighted avg       0.24      0.27      0.23      1128

Average accuracy = 0.2695035460992907

********** Run complete **********

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

********** Run - model: bert-base-uncased, learning rate = 2e-05 **********

********** Run 3 - input sentence pairs and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:49<05:10, 12.29it/s]{'loss': 1.667, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:45<03:28, 12.19it/s]{'eval_loss': 1.4305821657180786, 'eval_runtime': 2.0815, 'eval_samples_per_second': 657.699, 'eval_steps_per_second': 82.633, 'epoch': 1.0}

{'loss': 1.1827, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:36<01:43, 12.34it/s]{'eval_loss': 1.1723353862762451, 'eval_runtime': 2.0756, 'eval_samples_per_second': 659.563, 'eval_steps_per_second': 82.867, 'epoch': 2.0}

{'loss': 0.9042, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:29<00:00, 12.25it/s]{'eval_loss': 1.1611422300338745, 'eval_runtime': 2.0708, 'eval_samples_per_second': 661.091, 'eval_steps_per_second': 83.059, 'epoch': 3.0}

{'loss': 0.7168, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.1728566884994507, 'eval_runtime': 2.0763, 'eval_samples_per_second': 659.332, 'eval_steps_per_second': 82.838, 'epoch': 4.0}

{'train_runtime': 451.2858, 'train_samples_per_second': 90.249, 'train_steps_per_second': 11.283, 'train_loss': 1.1176700517125515, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.6914893617021277

                        precision    recall  f1-score   support

       Acknowledgement       0.77      0.82      0.79       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.41      0.39      0.40        33

               Comment       0.63      0.68      0.65       165

           Conditional       0.64      0.50      0.56        18

          Continuation       0.57      0.53      0.55       113

              Contrast       0.53      0.41      0.46        44

            Correction       1.00      0.19      0.32        21

           Elaboration       0.52      0.65      0.58       101

           Explanation       0.40      0.39      0.39        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.75      0.40      0.52        15

                Q_Elab       0.64      0.67      0.65        72

  Question_answer_pair       0.88      0.92      0.90       305

                Result       0.45      0.45      0.45        29

              accuracy                           0.69      1128

             macro avg       0.57      0.49      0.51      1128

          weighted avg       0.69      0.69      0.68      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:49<05:10, 12.32it/s]{'loss': 1.6545, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:44<03:28, 12.20it/s]{'eval_loss': 1.3967528343200684, 'eval_runtime': 2.0756, 'eval_samples_per_second': 659.571, 'eval_steps_per_second': 82.868, 'epoch': 1.0}

{'loss': 1.1545, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:36<01:43, 12.30it/s]{'eval_loss': 1.1816973686218262, 'eval_runtime': 2.0711, 'eval_samples_per_second': 661.015, 'eval_steps_per_second': 83.049, 'epoch': 2.0}

{'loss': 0.8735, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:31<00:00, 12.24it/s]{'eval_loss': 1.156396508216858, 'eval_runtime': 2.0728, 'eval_samples_per_second': 660.471, 'eval_steps_per_second': 82.981, 'epoch': 3.0}

{'loss': 0.6862, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.1786608695983887, 'eval_runtime': 2.0695, 'eval_samples_per_second': 661.509, 'eval_steps_per_second': 83.111, 'epoch': 4.0}

{'train_runtime': 453.8715, 'train_samples_per_second': 89.735, 'train_steps_per_second': 11.219, 'train_loss': 1.092148210715798, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.6817375886524822

                        precision    recall  f1-score   support

       Acknowledgement       0.72      0.79      0.75       148

           Alternation       0.93      0.74      0.82        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.43      0.45      0.44        33

               Comment       0.64      0.65      0.64       165

           Conditional       0.60      0.67      0.63        18

          Continuation       0.60      0.51      0.56       113

              Contrast       0.46      0.39      0.42        44

            Correction       0.50      0.29      0.36        21

           Elaboration       0.54      0.60      0.57       101

           Explanation       0.27      0.32      0.29        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.62      0.53      0.57        15

                Q_Elab       0.67      0.69      0.68        72

  Question_answer_pair       0.89      0.91      0.90       305

                Result       0.50      0.55      0.52        29

              accuracy                           0.68      1128

             macro avg       0.52      0.51      0.51      1128

          weighted avg       0.67      0.68      0.68      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:50<05:09, 12.33it/s]{'loss': 1.6545, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:43<03:28, 12.22it/s]{'eval_loss': 1.3967528343200684, 'eval_runtime': 2.0993, 'eval_samples_per_second': 652.126, 'eval_steps_per_second': 81.933, 'epoch': 1.0}

{'loss': 1.1545, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:35<01:42, 12.37it/s]{'eval_loss': 1.1816973686218262, 'eval_runtime': 2.0753, 'eval_samples_per_second': 659.666, 'eval_steps_per_second': 82.88, 'epoch': 2.0}

{'loss': 0.8735, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:30<00:00, 12.30it/s]{'eval_loss': 1.156396508216858, 'eval_runtime': 2.0868, 'eval_samples_per_second': 656.032, 'eval_steps_per_second': 82.423, 'epoch': 3.0}

{'loss': 0.6862, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.1786608695983887, 'eval_runtime': 2.0793, 'eval_samples_per_second': 658.399, 'eval_steps_per_second': 82.721, 'epoch': 4.0}

{'train_runtime': 452.6699, 'train_samples_per_second': 89.973, 'train_steps_per_second': 11.249, 'train_loss': 1.092148210715798, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.6817375886524822

                        precision    recall  f1-score   support

       Acknowledgement       0.72      0.79      0.75       148

           Alternation       0.93      0.74      0.82        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.43      0.45      0.44        33

               Comment       0.64      0.65      0.64       165

           Conditional       0.60      0.67      0.63        18

          Continuation       0.60      0.51      0.56       113

              Contrast       0.46      0.39      0.42        44

            Correction       0.50      0.29      0.36        21

           Elaboration       0.54      0.60      0.57       101

           Explanation       0.27      0.32      0.29        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.62      0.53      0.57        15

                Q_Elab       0.67      0.69      0.68        72

  Question_answer_pair       0.89      0.91      0.90       305

                Result       0.50      0.55      0.52        29

              accuracy                           0.68      1128

             macro avg       0.52      0.51      0.51      1128

          weighted avg       0.67      0.68      0.68      1128

Average accuracy = 0.6849881796690308

********** Run complete **********

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

********** Run - model: bert-base-uncased, learning rate = 2e-05 **********

********** Run 4 - masked speakers, input sentence pairs and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:51<05:11, 12.28it/s]{'loss': 1.6053, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:48<03:29, 12.18it/s]{'eval_loss': 2.3966610431671143, 'eval_runtime': 2.1007, 'eval_samples_per_second': 651.686, 'eval_steps_per_second': 81.877, 'epoch': 1.0}

{'loss': 1.1087, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:40<01:43, 12.28it/s]{'eval_loss': 2.5801494121551514, 'eval_runtime': 2.0654, 'eval_samples_per_second': 662.811, 'eval_steps_per_second': 83.275, 'epoch': 2.0}

{'loss': 0.834, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:36<00:00, 12.21it/s]{'eval_loss': 2.2506160736083984, 'eval_runtime': 2.0711, 'eval_samples_per_second': 661.001, 'eval_steps_per_second': 83.048, 'epoch': 3.0}

{'loss': 0.6476, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.526549816131592, 'eval_runtime': 2.1, 'eval_samples_per_second': 651.904, 'eval_steps_per_second': 81.905, 'epoch': 4.0}

{'train_runtime': 458.7098, 'train_samples_per_second': 88.788, 'train_steps_per_second': 11.101, 'train_loss': 1.0489043709993924, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.3404255319148936

                        precision    recall  f1-score   support

       Acknowledgement       1.00      0.01      0.01       148

           Alternation       0.94      0.79      0.86        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.35      0.42      0.38        33

               Comment       0.54      0.54      0.54       165

           Conditional       0.35      0.67      0.46        18

          Continuation       0.26      0.61      0.37       113

              Contrast       0.45      0.41      0.43        44

            Correction       0.12      0.29      0.17        21

           Elaboration       0.20      0.66      0.31       101

           Explanation       0.22      0.58      0.32        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.75      0.20      0.32        15

                Q_Elab       0.64      0.29      0.40        72

  Question_answer_pair       0.97      0.12      0.22       305

                Result       0.38      0.45      0.41        29

              accuracy                           0.34      1128

             macro avg       0.45      0.38      0.33      1128

          weighted avg       0.64      0.34      0.31      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:51<05:11, 12.27it/s]{'loss': 1.6948, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:46<03:29, 12.14it/s]{'eval_loss': 2.5359480381011963, 'eval_runtime': 2.0732, 'eval_samples_per_second': 660.341, 'eval_steps_per_second': 82.965, 'epoch': 1.0}

{'loss': 1.1778, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:39<01:45, 12.04it/s]{'eval_loss': 2.446014165878296, 'eval_runtime': 2.0695, 'eval_samples_per_second': 661.516, 'eval_steps_per_second': 83.112, 'epoch': 2.0}

{'loss': 0.8957, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:35<00:00, 12.28it/s]{'eval_loss': 2.2663376331329346, 'eval_runtime': 2.072, 'eval_samples_per_second': 660.714, 'eval_steps_per_second': 83.011, 'epoch': 3.0}

{'loss': 0.7085, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.6442790031433105, 'eval_runtime': 2.0748, 'eval_samples_per_second': 659.827, 'eval_steps_per_second': 82.9, 'epoch': 4.0}

{'train_runtime': 457.6497, 'train_samples_per_second': 88.994, 'train_steps_per_second': 11.126, 'train_loss': 1.1191625602584323, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.325354609929078

                        precision    recall  f1-score   support

       Acknowledgement       1.00      0.01      0.01       148

           Alternation       0.75      0.79      0.77        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.35      0.33      0.34        33

               Comment       0.53      0.56      0.54       165

           Conditional       0.33      0.72      0.46        18

          Continuation       0.27      0.57      0.36       113

              Contrast       0.53      0.43      0.48        44

            Correction       0.12      0.19      0.15        21

           Elaboration       0.20      0.65      0.30       101

           Explanation       0.14      0.55      0.22        31

             Narration       0.00      0.00      0.00        13

              Parallel       1.00      0.20      0.33        15

                Q_Elab       0.67      0.25      0.36        72

  Question_answer_pair       0.97      0.11      0.19       305

                Result       0.41      0.38      0.39        29

              accuracy                           0.33      1128

             macro avg       0.45      0.36      0.31      1128

          weighted avg       0.64      0.33      0.29      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:49<05:11, 12.27it/s]{'loss': 1.6948, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

 29%|██▉       | 1501/5092 [02:18<1:18:29,  1.31s/it]

                                                   

 50%|█████     | 2546/5092 [03:51<03:29, 12.17it/s]{'eval_loss': 2.5359480381011963, 'eval_runtime': 2.074, 'eval_samples_per_second': 660.074, 'eval_steps_per_second': 82.931, 'epoch': 1.0}

{'loss': 1.1778, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:44<01:43, 12.24it/s]{'eval_loss': 2.446014165878296, 'eval_runtime': 2.0729, 'eval_samples_per_second': 660.415, 'eval_steps_per_second': 82.974, 'epoch': 2.0}

{'loss': 0.8957, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:39<00:00, 12.17it/s]{'eval_loss': 2.2663376331329346, 'eval_runtime': 2.0792, 'eval_samples_per_second': 658.431, 'eval_steps_per_second': 82.725, 'epoch': 3.0}

{'loss': 0.7085, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.6442790031433105, 'eval_runtime': 2.106, 'eval_samples_per_second': 650.043, 'eval_steps_per_second': 81.671, 'epoch': 4.0}

{'train_runtime': 461.6579, 'train_samples_per_second': 88.221, 'train_steps_per_second': 11.03, 'train_loss': 1.1191625602584323, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.325354609929078

                        precision    recall  f1-score   support

       Acknowledgement       1.00      0.01      0.01       148

           Alternation       0.75      0.79      0.77        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.35      0.33      0.34        33

               Comment       0.53      0.56      0.54       165

           Conditional       0.33      0.72      0.46        18

          Continuation       0.27      0.57      0.36       113

              Contrast       0.53      0.43      0.48        44

            Correction       0.12      0.19      0.15        21

           Elaboration       0.20      0.65      0.30       101

           Explanation       0.14      0.55      0.22        31

             Narration       0.00      0.00      0.00        13

              Parallel       1.00      0.20      0.33        15

                Q_Elab       0.67      0.25      0.36        72

  Question_answer_pair       0.97      0.11      0.19       305

                Result       0.41      0.38      0.39        29

              accuracy                           0.33      1128

             macro avg       0.45      0.36      0.31      1128

          weighted avg       0.64      0.33      0.29      1128

Average accuracy = 0.3303782505910165

********** Run complete **********

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

********** Run - model: bert-base-uncased, learning rate = 2e-05 **********

********** Run 5 - input sentence pairs, distance and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:51<05:11, 12.25it/s]{'loss': 1.7502, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:48<03:30, 12.11it/s]{'eval_loss': 1.4075270891189575, 'eval_runtime': 2.1216, 'eval_samples_per_second': 645.253, 'eval_steps_per_second': 81.069, 'epoch': 1.0}

{'loss': 1.2226, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:41<01:46, 11.94it/s]{'eval_loss': 1.2600584030151367, 'eval_runtime': 2.1516, 'eval_samples_per_second': 636.282, 'eval_steps_per_second': 79.942, 'epoch': 2.0}

{'loss': 0.9654, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:37<00:00, 12.11it/s]{'eval_loss': 1.2736468315124512, 'eval_runtime': 2.1166, 'eval_samples_per_second': 646.803, 'eval_steps_per_second': 81.264, 'epoch': 3.0}

{'loss': 0.7644, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3070604801177979, 'eval_runtime': 2.1158, 'eval_samples_per_second': 647.027, 'eval_steps_per_second': 81.292, 'epoch': 4.0}

{'train_runtime': 459.9019, 'train_samples_per_second': 88.558, 'train_steps_per_second': 11.072, 'train_loss': 1.1756668390482312, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.650709219858156

                        precision    recall  f1-score   support

       Acknowledgement       0.71      0.77      0.74       148

           Alternation       1.00      0.84      0.91        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.44      0.52      0.47        33

               Comment       0.61      0.64      0.63       165

           Conditional       0.60      0.50      0.55        18

          Continuation       0.52      0.44      0.48       113

              Contrast       0.49      0.39      0.43        44

            Correction       0.50      0.10      0.16        21

           Elaboration       0.47      0.53      0.50       101

           Explanation       0.31      0.39      0.34        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.75      0.40      0.52        15

                Q_Elab       0.59      0.64      0.61        72

  Question_answer_pair       0.84      0.89      0.86       305

                Result       0.56      0.52      0.54        29

              accuracy                           0.65      1128

             macro avg       0.52      0.47      0.48      1128

          weighted avg       0.64      0.65      0.64      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:50<05:12, 12.21it/s]{'loss': 1.7743, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:46<03:30, 12.10it/s]{'eval_loss': 1.4453970193862915, 'eval_runtime': 2.1192, 'eval_samples_per_second': 645.988, 'eval_steps_per_second': 81.161, 'epoch': 1.0}

{'loss': 1.2495, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:39<01:45, 12.10it/s]{'eval_loss': 1.2796833515167236, 'eval_runtime': 2.1149, 'eval_samples_per_second': 647.314, 'eval_steps_per_second': 81.328, 'epoch': 2.0}

{'loss': 0.9816, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:35<00:00, 12.23it/s]{'eval_loss': 1.2776967287063599, 'eval_runtime': 2.1221, 'eval_samples_per_second': 645.125, 'eval_steps_per_second': 81.053, 'epoch': 3.0}

{'loss': 0.7919, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.2998497486114502, 'eval_runtime': 2.1164, 'eval_samples_per_second': 646.855, 'eval_steps_per_second': 81.27, 'epoch': 4.0}

{'train_runtime': 457.9816, 'train_samples_per_second': 88.929, 'train_steps_per_second': 11.118, 'train_loss': 1.1993307876287251, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.6551418439716312

                        precision    recall  f1-score   support

       Acknowledgement       0.70      0.76      0.73       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.43      0.55      0.48        33

               Comment       0.61      0.64      0.62       165

           Conditional       0.60      0.50      0.55        18

          Continuation       0.54      0.43      0.48       113

              Contrast       0.46      0.39      0.42        44

            Correction       0.60      0.14      0.23        21

           Elaboration       0.49      0.50      0.49       101

           Explanation       0.34      0.45      0.39        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.67      0.40      0.50        15

                Q_Elab       0.58      0.67      0.62        72

  Question_answer_pair       0.85      0.91      0.88       305

                Result       0.56      0.52      0.54        29

              accuracy                           0.66      1128

             macro avg       0.53      0.48      0.49      1128

          weighted avg       0.65      0.66      0.65      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:51<05:19, 11.94it/s]{'loss': 1.7743, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:47<03:30, 12.10it/s]{'eval_loss': 1.4453970193862915, 'eval_runtime': 2.119, 'eval_samples_per_second': 646.059, 'eval_steps_per_second': 81.17, 'epoch': 1.0}

{'loss': 1.2495, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:40<01:44, 12.23it/s]{'eval_loss': 1.2796833515167236, 'eval_runtime': 2.1234, 'eval_samples_per_second': 644.732, 'eval_steps_per_second': 81.004, 'epoch': 2.0}

{'loss': 0.9816, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:37<00:00, 12.10it/s]{'eval_loss': 1.2776967287063599, 'eval_runtime': 2.1206, 'eval_samples_per_second': 645.572, 'eval_steps_per_second': 81.109, 'epoch': 3.0}

{'loss': 0.7919, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.2998497486114502, 'eval_runtime': 2.1172, 'eval_samples_per_second': 646.609, 'eval_steps_per_second': 81.239, 'epoch': 4.0}

{'train_runtime': 459.6192, 'train_samples_per_second': 88.612, 'train_steps_per_second': 11.079, 'train_loss': 1.1993307876287251, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.6551418439716312

                        precision    recall  f1-score   support

       Acknowledgement       0.70      0.76      0.73       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.43      0.55      0.48        33

               Comment       0.61      0.64      0.62       165

           Conditional       0.60      0.50      0.55        18

          Continuation       0.54      0.43      0.48       113

              Contrast       0.46      0.39      0.42        44

            Correction       0.60      0.14      0.23        21

           Elaboration       0.49      0.50      0.49       101

           Explanation       0.34      0.45      0.39        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.67      0.40      0.50        15

                Q_Elab       0.58      0.67      0.62        72

  Question_answer_pair       0.85      0.91      0.88       305

                Result       0.56      0.52      0.54        29

              accuracy                           0.66      1128

             macro avg       0.53      0.48      0.49      1128

          weighted avg       0.65      0.66      0.65      1128

Average accuracy = 0.6536643026004728

********** Run complete **********

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

********** Run - model: bert-base-uncased, learning rate = 2e-05 **********

********** Run 6 - masked speakers, input sentence pairs, distance and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:51<05:10, 12.31it/s]{'loss': 1.7526, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:47<03:29, 12.16it/s]{'eval_loss': 1.4525237083435059, 'eval_runtime': 2.1117, 'eval_samples_per_second': 648.3, 'eval_steps_per_second': 81.452, 'epoch': 1.0}

{'loss': 1.242, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:39<01:43, 12.26it/s]{'eval_loss': 1.2768183946609497, 'eval_runtime': 2.1405, 'eval_samples_per_second': 639.584, 'eval_steps_per_second': 80.357, 'epoch': 2.0}

{'loss': 0.9755, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:35<00:00, 12.17it/s]{'eval_loss': 1.268926739692688, 'eval_runtime': 2.1109, 'eval_samples_per_second': 648.536, 'eval_steps_per_second': 81.482, 'epoch': 3.0}

{'loss': 0.7869, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.2890969514846802, 'eval_runtime': 2.1117, 'eval_samples_per_second': 648.292, 'eval_steps_per_second': 81.451, 'epoch': 4.0}

{'train_runtime': 457.4411, 'train_samples_per_second': 89.034, 'train_steps_per_second': 11.131, 'train_loss': 1.1892403529932063, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.6480496453900709

                        precision    recall  f1-score   support

       Acknowledgement       0.70      0.78      0.74       148

           Alternation       0.94      0.84      0.89        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.43      0.48      0.46        33

               Comment       0.64      0.63      0.63       165

           Conditional       0.61      0.61      0.61        18

          Continuation       0.44      0.35      0.39       113

              Contrast       0.45      0.43      0.44        44

            Correction       0.60      0.14      0.23        21

           Elaboration       0.47      0.48      0.47       101

           Explanation       0.32      0.39      0.35        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.50      0.33      0.40        15

                Q_Elab       0.59      0.67      0.63        72

  Question_answer_pair       0.85      0.91      0.88       305

                Result       0.48      0.55      0.52        29

              accuracy                           0.65      1128

             macro avg       0.50      0.48      0.48      1128

          weighted avg       0.63      0.65      0.64      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:50<05:13, 12.17it/s]{'loss': 1.6838, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:46<03:29, 12.15it/s]{'eval_loss': 1.4264236688613892, 'eval_runtime': 2.1419, 'eval_samples_per_second': 639.153, 'eval_steps_per_second': 80.303, 'epoch': 1.0}

{'loss': 1.1964, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:38<01:43, 12.28it/s]{'eval_loss': 1.2657405138015747, 'eval_runtime': 2.1101, 'eval_samples_per_second': 648.792, 'eval_steps_per_second': 81.514, 'epoch': 2.0}

{'loss': 0.9344, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:34<00:00, 12.14it/s]{'eval_loss': 1.2732176780700684, 'eval_runtime': 2.1115, 'eval_samples_per_second': 648.356, 'eval_steps_per_second': 81.459, 'epoch': 3.0}

{'loss': 0.734, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3006891012191772, 'eval_runtime': 2.106, 'eval_samples_per_second': 650.033, 'eval_steps_per_second': 81.67, 'epoch': 4.0}

{'train_runtime': 456.7985, 'train_samples_per_second': 89.16, 'train_steps_per_second': 11.147, 'train_loss': 1.1371238091192373, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Accuracy: 0.650709219858156

                        precision    recall  f1-score   support

       Acknowledgement       0.72      0.76      0.74       148

           Alternation       1.00      0.84      0.91        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.42      0.52      0.47        33

               Comment       0.62      0.59      0.60       165

           Conditional       0.60      0.50      0.55        18

          Continuation       0.53      0.44      0.48       113

              Contrast       0.41      0.39      0.40        44

            Correction       0.60      0.14      0.23        21

           Elaboration       0.50      0.50      0.50       101

           Explanation       0.33      0.42      0.37        31

             Narration       0.00      0.00      0.00        13

              Parallel       1.00      0.40      0.57        15

                Q_Elab       0.57      0.67      0.62        72

  Question_answer_pair       0.83      0.92      0.87       305

                Result       0.39      0.45      0.42        29

              accuracy                           0.65      1128

             macro avg       0.53      0.47      0.48      1128

          weighted avg       0.64      0.65      0.64      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:50<05:11, 12.27it/s]{'loss': 1.6838, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:46<03:29, 12.16it/s]{'eval_loss': 1.4264236688613892, 'eval_runtime': 2.1402, 'eval_samples_per_second': 639.661, 'eval_steps_per_second': 80.367, 'epoch': 1.0}

{'loss': 1.1964, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [05:38<01:43, 12.27it/s]{'eval_loss': 1.2657405138015747, 'eval_runtime': 2.1096, 'eval_samples_per_second': 648.934, 'eval_steps_per_second': 81.532, 'epoch': 2.0}

{'loss': 0.9344, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [07:34<00:00, 12.18it/s]{'eval_loss': 1.2732176780700684, 'eval_runtime': 2.1099, 'eval_samples_per_second': 648.851, 'eval_steps_per_second': 81.521, 'epoch': 3.0}

{'loss': 0.734, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3006891012191772, 'eval_runtime': 2.1101, 'eval_samples_per_second': 648.798, 'eval_steps_per_second': 81.514, 'epoch': 4.0}

{'train_runtime': 456.9811, 'train_samples_per_second': 89.124, 'train_steps_per_second': 11.143, 'train_loss': 1.1371238091192373, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.650709219858156

                        precision    recall  f1-score   support

       Acknowledgement       0.72      0.76      0.74       148

           Alternation       1.00      0.84      0.91        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.42      0.52      0.47        33

               Comment       0.62      0.59      0.60       165

           Conditional       0.60      0.50      0.55        18

          Continuation       0.53      0.44      0.48       113

              Contrast       0.41      0.39      0.40        44

            Correction       0.60      0.14      0.23        21

           Elaboration       0.50      0.50      0.50       101

           Explanation       0.33      0.42      0.37        31

             Narration       0.00      0.00      0.00        13

              Parallel       1.00      0.40      0.57        15

                Q_Elab       0.57      0.67      0.62        72

  Question_answer_pair       0.83      0.92      0.87       305

                Result       0.39      0.45      0.42        29

              accuracy                           0.65      1128

             macro avg       0.53      0.47      0.48      1128

          weighted avg       0.64      0.65      0.64      1128

Average accuracy = 0.649822695035461

********** Run complete **********

