Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

********** Run - model: gpt2, learning rate = 2e-05 **********

********** Run 1 - input sentence pairs **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:18<03:42, 17.16it/s]{'loss': 1.7905, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [02:44<02:24, 17.61it/s]{'eval_loss': 1.4126135110855103, 'eval_runtime': 2.025, 'eval_samples_per_second': 676.055, 'eval_steps_per_second': 84.939, 'epoch': 1.0}

{'loss': 1.2498, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:04<01:11, 17.77it/s]{'eval_loss': 1.1847901344299316, 'eval_runtime': 2.0282, 'eval_samples_per_second': 674.969, 'eval_steps_per_second': 84.803, 'epoch': 2.0}

{'loss': 1.0568, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [05:29<00:00, 17.69it/s]{'eval_loss': 1.1760348081588745, 'eval_runtime': 2.0312, 'eval_samples_per_second': 673.995, 'eval_steps_per_second': 84.68, 'epoch': 3.0}

{'loss': 0.9389, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.1813445091247559, 'eval_runtime': 2.0251, 'eval_samples_per_second': 676.013, 'eval_steps_per_second': 84.934, 'epoch': 4.0}

{'train_runtime': 331.5861, 'train_samples_per_second': 122.828, 'train_steps_per_second': 15.356, 'train_loss': 1.2589808222073227, 'epoch': 4.0}

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.674645390070922

                        precision    recall  f1-score   support

       Acknowledgement       0.72      0.82      0.77       148

           Alternation       0.94      0.79      0.86        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.39      0.36      0.38        33

               Comment       0.60      0.65      0.63       165

           Conditional       0.55      0.67      0.60        18

          Continuation       0.53      0.48      0.50       113

              Contrast       0.59      0.39      0.47        44

            Correction       0.67      0.19      0.30        21

           Elaboration       0.56      0.64      0.60       101

           Explanation       0.38      0.32      0.35        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.75      0.40      0.52        15

                Q_Elab       0.60      0.69      0.64        72

  Question_answer_pair       0.87      0.91      0.89       305

                Result       0.45      0.31      0.37        29

              accuracy                           0.67      1128

             macro avg       0.54      0.48      0.49      1128

          weighted avg       0.66      0.67      0.66      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:18<03:46, 16.89it/s]{'loss': 1.7723, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [02:44<02:23, 17.73it/s]{'eval_loss': 1.3979588747024536, 'eval_runtime': 2.0208, 'eval_samples_per_second': 677.46, 'eval_steps_per_second': 85.115, 'epoch': 1.0}

{'loss': 1.2267, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:05<01:12, 17.66it/s]{'eval_loss': 1.2083392143249512, 'eval_runtime': 2.022, 'eval_samples_per_second': 677.054, 'eval_steps_per_second': 85.064, 'epoch': 2.0}

{'loss': 1.0363, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [05:28<00:00, 17.76it/s]{'eval_loss': 1.187679648399353, 'eval_runtime': 2.0193, 'eval_samples_per_second': 677.964, 'eval_steps_per_second': 85.179, 'epoch': 3.0}

{'loss': 0.9224, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.2071651220321655, 'eval_runtime': 2.0213, 'eval_samples_per_second': 677.289, 'eval_steps_per_second': 85.094, 'epoch': 4.0}

{'train_runtime': 330.7308, 'train_samples_per_second': 123.145, 'train_steps_per_second': 15.396, 'train_loss': 1.239421236168561, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.6710992907801419

                        precision    recall  f1-score   support

       Acknowledgement       0.68      0.84      0.75       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.36      0.39      0.38        33

               Comment       0.65      0.62      0.63       165

           Conditional       0.46      0.72      0.57        18

          Continuation       0.56      0.36      0.44       113

              Contrast       0.62      0.41      0.49        44

            Correction       0.50      0.24      0.32        21

           Elaboration       0.50      0.68      0.58       101

           Explanation       0.54      0.42      0.47        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.56      0.33      0.42        15

                Q_Elab       0.64      0.69      0.67        72

  Question_answer_pair       0.86      0.91      0.89       305

                Result       0.40      0.34      0.37        29

              accuracy                           0.67      1128

             macro avg       0.52      0.49      0.49      1128

          weighted avg       0.66      0.67      0.66      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:18<03:36, 17.66it/s]{'loss': 1.7723, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [02:45<02:24, 17.66it/s]{'eval_loss': 1.3979588747024536, 'eval_runtime': 2.0234, 'eval_samples_per_second': 676.57, 'eval_steps_per_second': 85.004, 'epoch': 1.0}

{'loss': 1.2267, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:05<01:12, 17.66it/s]{'eval_loss': 1.2083392143249512, 'eval_runtime': 2.0244, 'eval_samples_per_second': 676.249, 'eval_steps_per_second': 84.963, 'epoch': 2.0}

{'loss': 1.0363, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

 79%|███████▊  | 4002/5092 [04:24<21:04,  1.16s/it]

                                                   

100%|██████████| 5092/5092 [05:32<00:00, 17.77it/s]{'eval_loss': 1.187679648399353, 'eval_runtime': 2.0214, 'eval_samples_per_second': 677.254, 'eval_steps_per_second': 85.09, 'epoch': 3.0}

{'loss': 0.9224, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.2071651220321655, 'eval_runtime': 2.0235, 'eval_samples_per_second': 676.535, 'eval_steps_per_second': 84.999, 'epoch': 4.0}

{'train_runtime': 334.5195, 'train_samples_per_second': 121.751, 'train_steps_per_second': 15.222, 'train_loss': 1.239421236168561, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.6710992907801419

                        precision    recall  f1-score   support

       Acknowledgement       0.68      0.84      0.75       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.36      0.39      0.38        33

               Comment       0.65      0.62      0.63       165

           Conditional       0.46      0.72      0.57        18

          Continuation       0.56      0.36      0.44       113

              Contrast       0.62      0.41      0.49        44

            Correction       0.50      0.24      0.32        21

           Elaboration       0.50      0.68      0.58       101

           Explanation       0.54      0.42      0.47        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.56      0.33      0.42        15

                Q_Elab       0.64      0.69      0.67        72

  Question_answer_pair       0.86      0.91      0.89       305

                Result       0.40      0.34      0.37        29

              accuracy                           0.67      1128

             macro avg       0.52      0.49      0.49      1128

          weighted avg       0.66      0.67      0.66      1128

Average accuracy = 0.6722813238770685

********** Run complete **********

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

********** Run - model: gpt2, learning rate = 2e-05 **********

********** Run 2 - input sentence pairs **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:12<03:17, 19.34it/s]{'loss': 2.3376, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [02:30<02:11, 19.29it/s]{'eval_loss': 2.291248083114624, 'eval_runtime': 1.9446, 'eval_samples_per_second': 704.015, 'eval_steps_per_second': 88.452, 'epoch': 1.0}

{'loss': 2.1579, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [03:43<01:05, 19.38it/s]{'eval_loss': 2.3135814666748047, 'eval_runtime': 1.9526, 'eval_samples_per_second': 701.133, 'eval_steps_per_second': 88.09, 'epoch': 2.0}

{'loss': 2.0715, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [05:03<00:00, 19.37it/s]{'eval_loss': 2.302171230316162, 'eval_runtime': 1.9485, 'eval_samples_per_second': 702.575, 'eval_steps_per_second': 88.271, 'epoch': 3.0}

{'loss': 1.9937, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.323164701461792, 'eval_runtime': 1.939, 'eval_samples_per_second': 706.041, 'eval_steps_per_second': 88.706, 'epoch': 4.0}

{'train_runtime': 305.9417, 'train_samples_per_second': 133.123, 'train_steps_per_second': 16.644, 'train_loss': 2.140159828683474, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.2828014184397163

                        precision    recall  f1-score   support

       Acknowledgement       0.29      0.11      0.16       148

           Alternation       0.00      0.00      0.00        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.00      0.00      0.00        33

               Comment       0.23      0.73      0.35       165

           Conditional       0.00      0.00      0.00        18

          Continuation       0.29      0.08      0.12       113

              Contrast       0.08      0.02      0.04        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.19      0.15      0.17       101

           Explanation       0.00      0.00      0.00        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.00      0.00      0.00        15

                Q_Elab       0.00      0.00      0.00        72

  Question_answer_pair       0.38      0.51      0.44       305

                Result       0.00      0.00      0.00        29

              accuracy                           0.28      1128

             macro avg       0.09      0.10      0.08      1128

          weighted avg       0.22      0.28      0.22      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:13<03:17, 19.34it/s]{'loss': 2.3992, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

 29%|██▉       | 1502/5092 [01:33<1:00:46,  1.02s/it]

                                                   

 50%|█████     | 2546/5092 [02:33<02:11, 19.29it/s]{'eval_loss': 2.2955803871154785, 'eval_runtime': 1.9449, 'eval_samples_per_second': 703.902, 'eval_steps_per_second': 88.438, 'epoch': 1.0}

{'loss': 2.1603, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [03:47<01:05, 19.36it/s]{'eval_loss': 2.291999340057373, 'eval_runtime': 1.9445, 'eval_samples_per_second': 704.023, 'eval_steps_per_second': 88.453, 'epoch': 2.0}

{'loss': 2.0716, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [05:07<00:00, 19.34it/s]{'eval_loss': 2.3103089332580566, 'eval_runtime': 1.9426, 'eval_samples_per_second': 704.731, 'eval_steps_per_second': 88.542, 'epoch': 3.0}

{'loss': 1.9934, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.3022031784057617, 'eval_runtime': 1.9427, 'eval_samples_per_second': 704.703, 'eval_steps_per_second': 88.538, 'epoch': 4.0}

{'train_runtime': 309.1602, 'train_samples_per_second': 131.738, 'train_steps_per_second': 16.47, 'train_loss': 2.156149649189292, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.2898936170212766

                        precision    recall  f1-score   support

       Acknowledgement       0.29      0.16      0.20       148

           Alternation       0.00      0.00      0.00        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.00      0.00      0.00        33

               Comment       0.23      0.77      0.36       165

           Conditional       0.00      0.00      0.00        18

          Continuation       0.29      0.06      0.10       113

              Contrast       0.20      0.05      0.07        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.23      0.13      0.16       101

           Explanation       0.00      0.00      0.00        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.00      0.00      0.00        15

                Q_Elab       0.14      0.03      0.05        72

  Question_answer_pair       0.39      0.50      0.44       305

                Result       0.00      0.00      0.00        29

              accuracy                           0.29      1128

             macro avg       0.11      0.11      0.09      1128

          weighted avg       0.24      0.29      0.23      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:11<03:17, 19.34it/s]{'loss': 2.3992, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [02:28<02:12, 19.26it/s]{'eval_loss': 2.2955803871154785, 'eval_runtime': 1.9431, 'eval_samples_per_second': 704.546, 'eval_steps_per_second': 88.519, 'epoch': 1.0}

{'loss': 2.1603, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [03:42<01:05, 19.35it/s]{'eval_loss': 2.291999340057373, 'eval_runtime': 1.9414, 'eval_samples_per_second': 705.152, 'eval_steps_per_second': 88.595, 'epoch': 2.0}

{'loss': 2.0716, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

 79%|███████▊  | 4002/5092 [04:01<21:35,  1.19s/it]

                                                   

100%|██████████| 5092/5092 [05:03<00:00, 19.14it/s]{'eval_loss': 2.3103089332580566, 'eval_runtime': 1.9383, 'eval_samples_per_second': 706.291, 'eval_steps_per_second': 88.738, 'epoch': 3.0}

{'loss': 1.9934, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.3022031784057617, 'eval_runtime': 1.9404, 'eval_samples_per_second': 705.531, 'eval_steps_per_second': 88.642, 'epoch': 4.0}

{'train_runtime': 305.3254, 'train_samples_per_second': 133.392, 'train_steps_per_second': 16.677, 'train_loss': 2.156149649189292, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.2898936170212766

                        precision    recall  f1-score   support

       Acknowledgement       0.29      0.16      0.20       148

           Alternation       0.00      0.00      0.00        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.00      0.00      0.00        33

               Comment       0.23      0.77      0.36       165

           Conditional       0.00      0.00      0.00        18

          Continuation       0.29      0.06      0.10       113

              Contrast       0.20      0.05      0.07        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.23      0.13      0.16       101

           Explanation       0.00      0.00      0.00        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.00      0.00      0.00        15

                Q_Elab       0.14      0.03      0.05        72

  Question_answer_pair       0.39      0.50      0.44       305

                Result       0.00      0.00      0.00        29

              accuracy                           0.29      1128

             macro avg       0.11      0.11      0.09      1128

          weighted avg       0.24      0.29      0.23      1128

Average accuracy = 0.28752955082742315

********** Run complete **********

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

********** Run - model: gpt2, learning rate = 2e-05 **********

********** Run 3 - input sentence pairs and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:29<04:02, 15.72it/s]{'loss': 1.8686, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:04<02:45, 15.41it/s]{'eval_loss': 1.3849143981933594, 'eval_runtime': 2.3382, 'eval_samples_per_second': 585.486, 'eval_steps_per_second': 73.56, 'epoch': 1.0}

{'loss': 1.2662, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:34<01:21, 15.71it/s]{'eval_loss': 1.1973124742507935, 'eval_runtime': 2.311, 'eval_samples_per_second': 592.372, 'eval_steps_per_second': 74.425, 'epoch': 2.0}

{'loss': 1.0799, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:12<00:00, 15.46it/s]{'eval_loss': 1.1967251300811768, 'eval_runtime': 2.3053, 'eval_samples_per_second': 593.837, 'eval_steps_per_second': 74.609, 'epoch': 3.0}

{'loss': 0.9694, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.1947885751724243, 'eval_runtime': 2.3051, 'eval_samples_per_second': 593.893, 'eval_steps_per_second': 74.616, 'epoch': 4.0}

{'train_runtime': 374.3723, 'train_samples_per_second': 108.79, 'train_steps_per_second': 13.601, 'train_loss': 1.2960339326701198, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.6684397163120568

                        precision    recall  f1-score   support

       Acknowledgement       0.69      0.84      0.76       148

           Alternation       0.94      0.84      0.89        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.37      0.52      0.43        33

               Comment       0.65      0.62      0.63       165

           Conditional       0.55      0.67      0.60        18

          Continuation       0.56      0.42      0.48       113

              Contrast       0.53      0.36      0.43        44

            Correction       0.75      0.14      0.24        21

           Elaboration       0.53      0.62      0.57       101

           Explanation       0.45      0.42      0.43        31

             Narration       0.00      0.00      0.00        13

              Parallel       1.00      0.27      0.42        15

                Q_Elab       0.62      0.64      0.63        72

  Question_answer_pair       0.84      0.92      0.88       305

                Result       0.37      0.24      0.29        29

              accuracy                           0.67      1128

             macro avg       0.55      0.47      0.48      1128

          weighted avg       0.66      0.67      0.65      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:29<04:07, 15.44it/s]{'loss': 1.9265, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:03<02:42, 15.64it/s]{'eval_loss': 1.5522838830947876, 'eval_runtime': 2.3112, 'eval_samples_per_second': 592.342, 'eval_steps_per_second': 74.421, 'epoch': 1.0}

{'loss': 1.3553, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:35<01:22, 15.43it/s]{'eval_loss': 1.2937685251235962, 'eval_runtime': 2.3064, 'eval_samples_per_second': 593.569, 'eval_steps_per_second': 74.576, 'epoch': 2.0}

{'loss': 1.1635, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:09<00:00, 15.70it/s]{'eval_loss': 1.2345184087753296, 'eval_runtime': 2.3089, 'eval_samples_per_second': 592.915, 'eval_steps_per_second': 74.493, 'epoch': 3.0}

{'loss': 1.0472, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.2414251565933228, 'eval_runtime': 2.3084, 'eval_samples_per_second': 593.048, 'eval_steps_per_second': 74.51, 'epoch': 4.0}

{'train_runtime': 371.3562, 'train_samples_per_second': 109.674, 'train_steps_per_second': 13.712, 'train_loss': 1.373123564499153, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.6648936170212766

                        precision    recall  f1-score   support

       Acknowledgement       0.71      0.83      0.76       148

           Alternation       0.88      0.74      0.80        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.32      0.42      0.36        33

               Comment       0.63      0.66      0.65       165

           Conditional       0.53      0.44      0.48        18

          Continuation       0.59      0.47      0.52       113

              Contrast       0.57      0.27      0.37        44

            Correction       0.43      0.29      0.34        21

           Elaboration       0.49      0.68      0.57       101

           Explanation       0.36      0.29      0.32        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.57      0.27      0.36        15

                Q_Elab       0.60      0.62      0.61        72

  Question_answer_pair       0.85      0.90      0.88       305

                Result       0.77      0.34      0.48        29

              accuracy                           0.66      1128

             macro avg       0.52      0.45      0.47      1128

          weighted avg       0.66      0.66      0.65      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:28<04:07, 15.45it/s]{'loss': 1.9265, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:03<02:42, 15.65it/s]{'eval_loss': 1.5522838830947876, 'eval_runtime': 2.3018, 'eval_samples_per_second': 594.749, 'eval_steps_per_second': 74.724, 'epoch': 1.0}

{'loss': 1.3553, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:34<01:22, 15.47it/s]{'eval_loss': 1.2937685251235962, 'eval_runtime': 2.3027, 'eval_samples_per_second': 594.518, 'eval_steps_per_second': 74.695, 'epoch': 2.0}

{'loss': 1.1635, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:08<00:00, 15.69it/s]{'eval_loss': 1.2345184087753296, 'eval_runtime': 2.2993, 'eval_samples_per_second': 595.397, 'eval_steps_per_second': 74.805, 'epoch': 3.0}

{'loss': 1.0472, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.2414251565933228, 'eval_runtime': 2.3026, 'eval_samples_per_second': 594.554, 'eval_steps_per_second': 74.699, 'epoch': 4.0}

{'train_runtime': 370.3544, 'train_samples_per_second': 109.97, 'train_steps_per_second': 13.749, 'train_loss': 1.373123564499153, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.6648936170212766

                        precision    recall  f1-score   support

       Acknowledgement       0.71      0.83      0.76       148

           Alternation       0.88      0.74      0.80        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.32      0.42      0.36        33

               Comment       0.63      0.66      0.65       165

           Conditional       0.53      0.44      0.48        18

          Continuation       0.59      0.47      0.52       113

              Contrast       0.57      0.27      0.37        44

            Correction       0.43      0.29      0.34        21

           Elaboration       0.49      0.68      0.57       101

           Explanation       0.36      0.29      0.32        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.57      0.27      0.36        15

                Q_Elab       0.60      0.62      0.61        72

  Question_answer_pair       0.85      0.90      0.88       305

                Result       0.77      0.34      0.48        29

              accuracy                           0.66      1128

             macro avg       0.52      0.45      0.47      1128

          weighted avg       0.66      0.66      0.65      1128

Average accuracy = 0.6660756501182034

********** Run complete **********

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

********** Run - model: gpt2, learning rate = 2e-05 **********

********** Run 4 - masked speakers, input sentence pairs and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:29<04:05, 15.58it/s]{'loss': 1.9241, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:02<02:44, 15.45it/s]{'eval_loss': 1.9152131080627441, 'eval_runtime': 2.5132, 'eval_samples_per_second': 544.72, 'eval_steps_per_second': 68.438, 'epoch': 1.0}

{'loss': 1.342, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:32<01:20, 15.76it/s]{'eval_loss': 1.8224221467971802, 'eval_runtime': 2.4248, 'eval_samples_per_second': 564.578, 'eval_steps_per_second': 70.933, 'epoch': 2.0}

{'loss': 1.1415, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:05<00:00, 15.16it/s]{'eval_loss': 1.8481287956237793, 'eval_runtime': 2.4231, 'eval_samples_per_second': 564.968, 'eval_steps_per_second': 70.982, 'epoch': 3.0}

{'loss': 1.027, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 2.0218024253845215, 'eval_runtime': 2.3907, 'eval_samples_per_second': 572.629, 'eval_steps_per_second': 71.945, 'epoch': 4.0}

{'train_runtime': 367.5685, 'train_samples_per_second': 110.804, 'train_steps_per_second': 13.853, 'train_loss': 1.3586481638246883, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.4769503546099291

                        precision    recall  f1-score   support

       Acknowledgement       0.90      0.30      0.45       148

           Alternation       0.94      0.79      0.86        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.38      0.39      0.39        33

               Comment       0.55      0.60      0.58       165

           Conditional       0.26      0.61      0.37        18

          Continuation       0.27      0.52      0.36       113

              Contrast       0.37      0.39      0.38        44

            Correction       0.21      0.14      0.17        21

           Elaboration       0.29      0.60      0.39       101

           Explanation       0.33      0.45      0.38        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.75      0.20      0.32        15

                Q_Elab       0.51      0.64      0.57        72

  Question_answer_pair       0.97      0.47      0.63       305

                Result       0.34      0.34      0.34        29

              accuracy                           0.48      1128

             macro avg       0.44      0.40      0.39      1128

          weighted avg       0.62      0.48      0.49      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:27<04:06, 15.50it/s]{'loss': 1.9144, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:00<02:42, 15.71it/s]{'eval_loss': 1.5572975873947144, 'eval_runtime': 2.3935, 'eval_samples_per_second': 571.963, 'eval_steps_per_second': 71.861, 'epoch': 1.0}

{'loss': 1.3211, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:30<01:22, 15.44it/s]{'eval_loss': 1.5357415676116943, 'eval_runtime': 2.3947, 'eval_samples_per_second': 571.687, 'eval_steps_per_second': 71.826, 'epoch': 2.0}

{'loss': 1.1303, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:02<00:00, 15.76it/s]{'eval_loss': 1.409058928489685, 'eval_runtime': 2.3987, 'eval_samples_per_second': 570.731, 'eval_steps_per_second': 71.706, 'epoch': 3.0}

{'loss': 1.0058, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.4838107824325562, 'eval_runtime': 2.3953, 'eval_samples_per_second': 571.533, 'eval_steps_per_second': 71.807, 'epoch': 4.0}

{'train_runtime': 365.2737, 'train_samples_per_second': 111.5, 'train_steps_per_second': 13.94, 'train_loss': 1.3428823946033606, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.5638297872340425

                        precision    recall  f1-score   support

       Acknowledgement       0.84      0.52      0.64       148

           Alternation       0.70      0.74      0.72        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.29      0.45      0.36        33

               Comment       0.58      0.61      0.60       165

           Conditional       0.39      0.67      0.49        18

          Continuation       0.39      0.47      0.43       113

              Contrast       0.31      0.39      0.35        44

            Correction       0.29      0.19      0.23        21

           Elaboration       0.38      0.57      0.46       101

           Explanation       0.28      0.32      0.30        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.44      0.27      0.33        15

                Q_Elab       0.59      0.65      0.62        72

  Question_answer_pair       0.92      0.68      0.78       305

                Result       0.30      0.55      0.39        29

              accuracy                           0.56      1128

             macro avg       0.42      0.44      0.42      1128

          weighted avg       0.62      0.56      0.58      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:28<04:21, 14.61it/s]{'loss': 1.9144, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:01<02:42, 15.71it/s]{'eval_loss': 1.5572975873947144, 'eval_runtime': 2.3899, 'eval_samples_per_second': 572.834, 'eval_steps_per_second': 71.97, 'epoch': 1.0}

{'loss': 1.3211, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:32<01:22, 15.51it/s]{'eval_loss': 1.5357415676116943, 'eval_runtime': 2.3869, 'eval_samples_per_second': 573.542, 'eval_steps_per_second': 72.059, 'epoch': 2.0}

{'loss': 1.1303, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:05<00:00, 15.76it/s]{'eval_loss': 1.409058928489685, 'eval_runtime': 2.392, 'eval_samples_per_second': 572.334, 'eval_steps_per_second': 71.908, 'epoch': 3.0}

{'loss': 1.0058, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.4838107824325562, 'eval_runtime': 2.3896, 'eval_samples_per_second': 572.902, 'eval_steps_per_second': 71.979, 'epoch': 4.0}

{'train_runtime': 368.401, 'train_samples_per_second': 110.553, 'train_steps_per_second': 13.822, 'train_loss': 1.3428823946033606, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.5638297872340425

                        precision    recall  f1-score   support

       Acknowledgement       0.84      0.52      0.64       148

           Alternation       0.70      0.74      0.72        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.29      0.45      0.36        33

               Comment       0.58      0.61      0.60       165

           Conditional       0.39      0.67      0.49        18

          Continuation       0.39      0.47      0.43       113

              Contrast       0.31      0.39      0.35        44

            Correction       0.29      0.19      0.23        21

           Elaboration       0.38      0.57      0.46       101

           Explanation       0.28      0.32      0.30        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.44      0.27      0.33        15

                Q_Elab       0.59      0.65      0.62        72

  Question_answer_pair       0.92      0.68      0.78       305

                Result       0.30      0.55      0.39        29

              accuracy                           0.56      1128

             macro avg       0.42      0.44      0.42      1128

          weighted avg       0.62      0.56      0.58      1128

Average accuracy = 0.534869976359338

********** Run complete **********

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

********** Run - model: gpt2, learning rate = 2e-05 **********

********** Run 5 - input sentence pairs, distance and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:28<04:02, 15.77it/s]{'loss': 1.8863, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:04<02:45, 15.42it/s]{'eval_loss': 1.6162779331207275, 'eval_runtime': 2.3981, 'eval_samples_per_second': 570.866, 'eval_steps_per_second': 71.723, 'epoch': 1.0}

{'loss': 1.4147, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:34<01:20, 15.77it/s]{'eval_loss': 1.3775614500045776, 'eval_runtime': 2.4306, 'eval_samples_per_second': 563.235, 'eval_steps_per_second': 70.764, 'epoch': 2.0}

{'loss': 1.225, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

 79%|███████▊  | 4001/5092 [04:54<18:51,  1.04s/it]

                                                   

100%|██████████| 5092/5092 [06:10<00:00, 15.52it/s]{'eval_loss': 1.3473032712936401, 'eval_runtime': 2.4215, 'eval_samples_per_second': 565.355, 'eval_steps_per_second': 71.031, 'epoch': 3.0}

{'loss': 1.1077, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3436033725738525, 'eval_runtime': 2.3921, 'eval_samples_per_second': 572.307, 'eval_steps_per_second': 71.904, 'epoch': 4.0}

{'train_runtime': 372.7995, 'train_samples_per_second': 109.249, 'train_steps_per_second': 13.659, 'train_loss': 1.4084216625036823, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.6462765957446809

                        precision    recall  f1-score   support

       Acknowledgement       0.66      0.80      0.72       148

           Alternation       0.94      0.79      0.86        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.33      0.39      0.36        33

               Comment       0.63      0.62      0.62       165

           Conditional       0.50      0.39      0.44        18

          Continuation       0.56      0.35      0.43       113

              Contrast       0.62      0.36      0.46        44

            Correction       0.30      0.14      0.19        21

           Elaboration       0.46      0.58      0.52       101

           Explanation       0.38      0.45      0.41        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.83      0.33      0.48        15

                Q_Elab       0.56      0.75      0.64        72

  Question_answer_pair       0.85      0.89      0.87       305

                Result       0.48      0.45      0.46        29

              accuracy                           0.65      1128

             macro avg       0.51      0.46      0.47      1128

          weighted avg       0.64      0.65      0.63      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:28<04:06, 15.52it/s]{'loss': 1.94, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:03<02:42, 15.67it/s]{'eval_loss': 1.5537769794464111, 'eval_runtime': 2.3961, 'eval_samples_per_second': 571.346, 'eval_steps_per_second': 71.783, 'epoch': 1.0}

{'loss': 1.4154, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:34<01:22, 15.52it/s]{'eval_loss': 1.3518073558807373, 'eval_runtime': 2.4006, 'eval_samples_per_second': 570.268, 'eval_steps_per_second': 71.648, 'epoch': 2.0}

{'loss': 1.2287, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:10<00:00, 15.77it/s]{'eval_loss': 1.3196516036987305, 'eval_runtime': 2.3966, 'eval_samples_per_second': 571.236, 'eval_steps_per_second': 71.77, 'epoch': 3.0}

{'loss': 1.1136, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3082733154296875, 'eval_runtime': 2.3958, 'eval_samples_per_second': 571.411, 'eval_steps_per_second': 71.792, 'epoch': 4.0}

{'train_runtime': 372.9774, 'train_samples_per_second': 109.197, 'train_steps_per_second': 13.652, 'train_loss': 1.4244326271602514, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.6453900709219859

                        precision    recall  f1-score   support

       Acknowledgement       0.72      0.74      0.73       148

           Alternation       0.94      0.79      0.86        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.40      0.52      0.45        33

               Comment       0.59      0.65      0.62       165

           Conditional       0.50      0.50      0.50        18

          Continuation       0.49      0.35      0.41       113

              Contrast       0.74      0.45      0.56        44

            Correction       0.33      0.10      0.15        21

           Elaboration       0.49      0.51      0.50       101

           Explanation       0.44      0.39      0.41        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.62      0.33      0.43        15

                Q_Elab       0.56      0.67      0.61        72

  Question_answer_pair       0.83      0.91      0.87       305

                Result       0.31      0.45      0.37        29

              accuracy                           0.65      1128

             macro avg       0.50      0.46      0.47      1128

          weighted avg       0.63      0.65      0.63      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:28<04:06, 15.51it/s]{'loss': 1.94, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:05<02:42, 15.71it/s]{'eval_loss': 1.5537769794464111, 'eval_runtime': 2.4239, 'eval_samples_per_second': 564.791, 'eval_steps_per_second': 70.96, 'epoch': 1.0}

{'loss': 1.4154, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:36<01:22, 15.52it/s]{'eval_loss': 1.3518073558807373, 'eval_runtime': 2.3948, 'eval_samples_per_second': 571.645, 'eval_steps_per_second': 71.821, 'epoch': 2.0}

{'loss': 1.2287, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

 79%|███████▊  | 4002/5092 [04:57<19:38,  1.08s/it]

                                                   

100%|██████████| 5092/5092 [06:13<00:00, 15.77it/s]{'eval_loss': 1.3196516036987305, 'eval_runtime': 2.3923, 'eval_samples_per_second': 572.246, 'eval_steps_per_second': 71.896, 'epoch': 3.0}

{'loss': 1.1136, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3082733154296875, 'eval_runtime': 2.4188, 'eval_samples_per_second': 565.972, 'eval_steps_per_second': 71.108, 'epoch': 4.0}

{'train_runtime': 375.7286, 'train_samples_per_second': 108.397, 'train_steps_per_second': 13.552, 'train_loss': 1.4244326271602514, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.6453900709219859

                        precision    recall  f1-score   support

       Acknowledgement       0.72      0.74      0.73       148

           Alternation       0.94      0.79      0.86        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.40      0.52      0.45        33

               Comment       0.59      0.65      0.62       165

           Conditional       0.50      0.50      0.50        18

          Continuation       0.49      0.35      0.41       113

              Contrast       0.74      0.45      0.56        44

            Correction       0.33      0.10      0.15        21

           Elaboration       0.49      0.51      0.50       101

           Explanation       0.44      0.39      0.41        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.62      0.33      0.43        15

                Q_Elab       0.56      0.67      0.61        72

  Question_answer_pair       0.83      0.91      0.87       305

                Result       0.31      0.45      0.37        29

              accuracy                           0.65      1128

             macro avg       0.50      0.46      0.47      1128

          weighted avg       0.63      0.65      0.63      1128

Average accuracy = 0.6456855791962175

********** Run complete **********

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

********** Run - model: gpt2, learning rate = 2e-05 **********

********** Run 6 - masked speakers, input sentence pairs, distance and question **********

Random seed = 42

                                                   

 25%|██▌       | 1273/5092 [01:30<04:03, 15.71it/s]{'loss': 1.9024, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:06<02:44, 15.44it/s]{'eval_loss': 1.6737432479858398, 'eval_runtime': 2.3995, 'eval_samples_per_second': 570.526, 'eval_steps_per_second': 71.68, 'epoch': 1.0}

{'loss': 1.4571, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:36<01:20, 15.75it/s]{'eval_loss': 1.4226351976394653, 'eval_runtime': 2.4037, 'eval_samples_per_second': 569.546, 'eval_steps_per_second': 71.557, 'epoch': 2.0}

{'loss': 1.2586, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:09<00:00, 15.51it/s]{'eval_loss': 1.3743410110473633, 'eval_runtime': 2.4024, 'eval_samples_per_second': 569.85, 'eval_steps_per_second': 71.595, 'epoch': 3.0}

{'loss': 1.1558, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3767726421356201, 'eval_runtime': 2.3974, 'eval_samples_per_second': 571.031, 'eval_steps_per_second': 71.744, 'epoch': 4.0}

{'train_runtime': 372.1479, 'train_samples_per_second': 109.44, 'train_steps_per_second': 13.683, 'train_loss': 1.443445437926527, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.6294326241134752

                        precision    recall  f1-score   support

       Acknowledgement       0.71      0.74      0.72       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.36      0.45      0.40        33

               Comment       0.59      0.68      0.63       165

           Conditional       0.48      0.61      0.54        18

          Continuation       0.54      0.37      0.44       113

              Contrast       0.62      0.41      0.49        44

            Correction       0.25      0.10      0.14        21

           Elaboration       0.41      0.53      0.47       101

           Explanation       0.42      0.32      0.36        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.38      0.20      0.26        15

                Q_Elab       0.57      0.72      0.63        72

  Question_answer_pair       0.83      0.84      0.83       305

                Result       0.43      0.34      0.38        29

              accuracy                           0.63      1128

             macro avg       0.47      0.44      0.45      1128

          weighted avg       0.62      0.63      0.62      1128

Random seed = 123

                                                   

 25%|██▌       | 1273/5092 [01:27<04:06, 15.50it/s]{'loss': 1.9637, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:00<02:42, 15.69it/s]{'eval_loss': 1.592850685119629, 'eval_runtime': 2.4355, 'eval_samples_per_second': 562.095, 'eval_steps_per_second': 70.621, 'epoch': 1.0}

{'loss': 1.4375, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:30<01:22, 15.49it/s]{'eval_loss': 1.4023178815841675, 'eval_runtime': 2.4056, 'eval_samples_per_second': 569.096, 'eval_steps_per_second': 71.501, 'epoch': 2.0}

{'loss': 1.2443, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:06<00:00, 15.68it/s]{'eval_loss': 1.33336341381073, 'eval_runtime': 2.4016, 'eval_samples_per_second': 570.047, 'eval_steps_per_second': 71.62, 'epoch': 3.0}

{'loss': 1.1338, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3452749252319336, 'eval_runtime': 2.4063, 'eval_samples_per_second': 568.917, 'eval_steps_per_second': 71.478, 'epoch': 4.0}

{'train_runtime': 369.3322, 'train_samples_per_second': 110.275, 'train_steps_per_second': 13.787, 'train_loss': 1.4448299243144884, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']

You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50258. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc

Accuracy: 0.6471631205673759

                        precision    recall  f1-score   support

       Acknowledgement       0.69      0.80      0.74       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.41      0.48      0.44        33

               Comment       0.62      0.67      0.64       165

           Conditional       0.55      0.61      0.58        18

          Continuation       0.58      0.35      0.44       113

              Contrast       0.58      0.34      0.43        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.45      0.54      0.49       101

           Explanation       0.39      0.39      0.39        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.50      0.27      0.35        15

                Q_Elab       0.53      0.67      0.59        72

  Question_answer_pair       0.82      0.90      0.86       305

                Result       0.50      0.41      0.45        29

              accuracy                           0.65      1128

             macro avg       0.48      0.45      0.46      1128

          weighted avg       0.63      0.65      0.63      1128

Random seed = 456

                                                   

 25%|██▌       | 1273/5092 [01:28<04:06, 15.50it/s]{'loss': 1.9637, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.0}

                                                   

                                                   

 50%|█████     | 2546/5092 [03:02<02:42, 15.69it/s]{'eval_loss': 1.592850685119629, 'eval_runtime': 2.4297, 'eval_samples_per_second': 563.437, 'eval_steps_per_second': 70.79, 'epoch': 1.0}

{'loss': 1.4375, 'learning_rate': 1e-05, 'epoch': 2.0}

                                                   

                                                   

 75%|███████▌  | 3819/5092 [04:32<01:22, 15.51it/s]{'eval_loss': 1.4023178815841675, 'eval_runtime': 2.3947, 'eval_samples_per_second': 571.668, 'eval_steps_per_second': 71.824, 'epoch': 2.0}

{'loss': 1.2443, 'learning_rate': 5e-06, 'epoch': 3.0}

                                                   

                                                   

100%|██████████| 5092/5092 [06:05<00:00, 15.74it/s]{'eval_loss': 1.33336341381073, 'eval_runtime': 2.4028, 'eval_samples_per_second': 569.744, 'eval_steps_per_second': 71.582, 'epoch': 3.0}

{'loss': 1.1338, 'learning_rate': 0.0, 'epoch': 4.0}

                                                   

                                                   

{'eval_loss': 1.3452749252319336, 'eval_runtime': 2.3954, 'eval_samples_per_second': 571.503, 'eval_steps_per_second': 71.803, 'epoch': 4.0}

{'train_runtime': 368.3237, 'train_samples_per_second': 110.577, 'train_steps_per_second': 13.825, 'train_loss': 1.4448299243144884, 'epoch': 4.0}

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

/lustre03/project/6066577/shuhaibm/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.

  _warn_prf(average, modifier, msg_start, len(result))

Accuracy: 0.6471631205673759

                        precision    recall  f1-score   support

       Acknowledgement       0.69      0.80      0.74       148

           Alternation       1.00      0.79      0.88        19

            Background       0.00      0.00      0.00         1

Clarification_question       0.41      0.48      0.44        33

               Comment       0.62      0.67      0.64       165

           Conditional       0.55      0.61      0.58        18

          Continuation       0.58      0.35      0.44       113

              Contrast       0.58      0.34      0.43        44

            Correction       0.00      0.00      0.00        21

           Elaboration       0.45      0.54      0.49       101

           Explanation       0.39      0.39      0.39        31

             Narration       0.00      0.00      0.00        13

              Parallel       0.50      0.27      0.35        15

                Q_Elab       0.53      0.67      0.59        72

  Question_answer_pair       0.82      0.90      0.86       305

                Result       0.50      0.41      0.45        29

              accuracy                           0.65      1128

             macro avg       0.48      0.45      0.46      1128

          weighted avg       0.63      0.65      0.63      1128

Average accuracy = 0.6412529550827424

********** Run complete **********

